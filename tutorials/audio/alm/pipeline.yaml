# ALM (Audio Language Model) Pipeline Configuration
#
# This config processes audio manifests to create training windows
# for Audio Language Models.
#
# Usage (from Curator repo root):
#   python tutorials/audio/alm/main.py \
#     --config-path . \
#     --config-name pipeline \
#     input_manifest=tests/fixtures/audio/alm/sample_input.jsonl
#
#   # Override values from command line
#   python tutorials/audio/alm/main.py \
#     --config-path . \
#     --config-name pipeline \
#     input_manifest=/data/input.jsonl \
#     processors.0.min_speakers=3 \
#     processors.1.overlap_percentage=30

defaults:
  - _self_
  - override hydra/job_logging: none
  - override hydra/hydra_logging: none

hydra:
  run:
    dir: .
  output_subdir: null

documentation: |
  ALM Data Pipeline
  #################
  This config processes audio manifests to create training windows
  for Audio Language Model training.

  It performs the following data processing:

  1. ALM Data Builder: Creates training windows from audio segments
     - Filters by sample rate, bandwidth, speaker count
     - Creates windows of target duration (120s ± 10%)

  2. ALM Data Overlap: Filters overlapping windows
     - Removes windows with high overlap
     - Keeps windows closest to target duration

  **Required arguments**:

  * **input_manifest**: Path to input JSONL manifest with audio segments

  **Output format**:

  This config generates output manifest at ``${output_dir}/alm_output.jsonl``

  Output manifest contains the following keys:

  * **audio_filepath (str)**: Path to the audio file
  * **windows (list)**: Training windows with segments and speaker durations
  * **filtered_windows (list)**: Windows after overlap filtering
  * **filtered_dur (float)**: Total duration of filtered windows
  * **stats (dict)**: Processing statistics

# Input manifest (JSONL with audio segments)
input_manifest: ???

# Output directory for results
output_dir: ./alm_output

# Processor chain definition
processors:
  # Stage 0: ALM Data Builder
  # Creates training windows from audio segments
  - _target_: nemo_curator.stages.audio.alm.ALMDataBuilderStage

    # Window duration: target ± (target * tolerance)
    # e.g., 120 ± 12 = 108-132 seconds
    target_window_duration: 120.0
    tolerance: 0.1

    # Audio quality requirements
    min_sample_rate: 16000
    min_bandwidth: 8000

    # Speaker constraints
    min_speakers: 2
    max_speakers: 5

    # Truncation behavior
    truncation: true

    # Fields to drop (comma-separated strings)
    drop_fields: "words"
    drop_fields_top_level: "words,segments"

  # Stage 1: ALM Data Overlap Filter
  # Filters windows based on overlap threshold
  - _target_: nemo_curator.stages.audio.alm.ALMDataOverlapStage

    # Overlap filtering (0 = aggressive, 100 = permissive)
    overlap_percentage: 50
    target_duration: 120.0
